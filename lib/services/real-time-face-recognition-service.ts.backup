
import { enhancedRekognitionService } from '@/lib/aws/rekognition-service';
import { webSocketService } from './websocket-service';
import { prisma } from '@/lib/db';

export interface VideoFrame {
  imageData: Buffer;
  timestamp: Date;
  cameraId: string;
  frameId: string;
  metadata?: any;
}

export interface RecognitionResult {
  frameId: string;
  cameraId: string;
  recognitions: Array<{
    childId: string;
    childName: string;
    confidence: number;
    boundingBox: any;
    zone?: string;
  }>;
  timestamp: Date;
  processingTime: number;
}

export interface CameraStreamConfig {
  cameraId: string;
  streamUrl: string;
  venueId: string;
  isActive: boolean;
  frameRate: number;
  recognitionThreshold: number;
  zone?: string;
}

export class RealTimeFaceRecognitionService {
  private static instance: RealTimeFaceRecognitionService;
  private processingQueue: Map<string, VideoFrame[]> = new Map();
  private activeStreams: Map<string, CameraStreamConfig> = new Map();
  private recognitionResults: Map<string, RecognitionResult[]> = new Map();
  private isProcessing = false;
  
  private constructor() {
    this.startProcessingLoop();
  }

  public static getInstance(): RealTimeFaceRecognitionService {
    if (!RealTimeFaceRecognitionService.instance) {
      RealTimeFaceRecognitionService.instance = new RealTimeFaceRecognitionService();
    }
    return RealTimeFaceRecognitionService.instance;
  }

  // Configure camera stream for real-time processing
  async configureCameraStream(config: CameraStreamConfig): Promise<{ success: boolean; message: string }> {
    try {
      // Validate camera exists and has proper access
      const camera = await prisma.camera.findFirst({
        where: { 
          id: config.cameraId,
          venueId: config.venueId,
          isActive: true 
        },
        include: { venue: true }
      });

      if (!camera) {
        return { success: false, message: 'Camera not found or inactive' };
      }

      this.activeStreams.set(config.cameraId, config);
      this.processingQueue.set(config.cameraId, []);

      console.log(`Camera stream configured for ${config.cameraId}`);
      return { success: true, message: 'Camera stream configured successfully' };
    } catch (error) {
      console.error('Error configuring camera stream:', error);
      return { success: false, message: 'Failed to configure camera stream' };
    }
  }

  // Add video frame to processing queue
  async addFrameToQueue(frame: VideoFrame): Promise<void> {
    const cameraQueue = this.processingQueue.get(frame.cameraId);
    if (!cameraQueue) {
      console.warn(`No queue found for camera ${frame.cameraId}`);
      return;
    }

    cameraQueue.push(frame);

    // Keep queue size manageable (max 10 frames per camera)
    if (cameraQueue.length > 10) {
      cameraQueue.shift(); // Remove oldest frame
    }
  }

  // Process frames for face recognition
  private async startProcessingLoop(): Promise<void> {
    setInterval(async () => {
      if (this.isProcessing) return;
      
      this.isProcessing = true;
      await this.processQueuedFrames();
      this.isProcessing = false;
    }, 2000); // Process every 2 seconds
  }

  private async processQueuedFrames(): Promise<void> {
    for (const [cameraId, frames] of this.processingQueue.entries()) {
      if (frames.length === 0) continue;

      const config = this.activeStreams.get(cameraId);
      if (!config || !config.isActive) continue;

      // Process latest frame
      const frame = frames.pop();
      if (!frame) continue;

      try {
        const startTime = Date.now();
        const result = await this.processFrameForRecognition(frame, config);
        const processingTime = Date.now() - startTime;

        if (result) {
          result.processingTime = processingTime;
          await this.handleRecognitionResult(result);
        }
      } catch (error) {
        console.error(`Error processing frame from camera ${cameraId}:`, error);
      }
    }
  }

  // Process single frame for face recognition
  private async processFrameForRecognition(
    frame: VideoFrame, 
    config: CameraStreamConfig
  ): Promise<RecognitionResult | null> {
    try {
      // Check if we should use demo mode
      if (await this.shouldUseDemoMode(config.venueId)) {
        return await this.processDemoFrameRecognition(frame, config);
      }

      // Get children registered at this venue
      const children = await prisma.child.findMany({
        where: {
          currentVenueId: config.venueId,
          faceRecognitionEnabled: true,
          biometricId: { not: null }
        },
        include: {
          venue: {
            select: { faceCollectionId: true }
          }
        }
      });

      if (children.length === 0) {
        return null;
      }

      // Get venue's face collection
      const venue = children[0]?.venue;
      if (!venue?.faceCollectionId) {
        console.warn(`No face collection configured for venue ${config.venueId}`);
        return null;
      }

      const recognitions = [];

      try {
        // Convert buffer to base64 for AWS Rekognition
        const base64Image = frame.imageData.toString('base64');
        const imageUrl = `data:image/jpeg;base64,${base64Image}`;
        
        const searchResult = await enhancedRekognitionService.searchFacesByImage(
          imageUrl,
          venue.faceCollectionId,
          config.recognitionThreshold
        );

        if (searchResult.success && searchResult.detections) {
          for (const detection of searchResult.detections) {
            if (detection.confidence >= config.recognitionThreshold && detection.childId) {
              // Find the child by external image ID pattern
              const child = children.find(c => 
                c.biometricData && 
                typeof c.biometricData === 'object' && 
                (c.biometricData as any).externalImageId?.includes(c.id)
              );

              if (child) {
                recognitions.push({
                  childId: child.id,
                  childName: `${child.firstName} ${child.lastName}`,
                  confidence: detection.confidence,
                  boundingBox: detection.boundingBox,
                  zone: config.zone
                });
              }
            }
          }
        }
      } catch (error) {
        console.error('AWS face recognition error:', error);
        
        // If AWS fails, fall back to demo mode for this venue
        if (error.name === 'AccessDeniedException' || error.message?.includes('not authorized')) {
          console.warn(`AWS permissions error for venue ${config.venueId}, switching to demo mode`);
          return await this.processDemoFrameRecognition(frame, config);
        }
        
        return null;
      }

      if (recognitions.length > 0) {
        return {
          frameId: frame.frameId,
          cameraId: frame.cameraId,
          recognitions,
          timestamp: frame.timestamp,
          processingTime: 0 // Will be set by caller
        };
      }

      return null;
    } catch (error) {
      console.error('Error in frame recognition processing:', error);
      return null;
    }
  }

  // Check if venue should use demo mode
  private async shouldUseDemoMode(venueId: string): Promise<boolean> {
    try {
      const venue = await prisma.venue.findUnique({
        where: { id: venueId },
        select: { 
          faceCollectionId: true,
          faceRecognitionEnabled: true 
        }
      });

      // Use demo mode if no collection configured or AWS not available
      return !venue?.faceCollectionId || !venue?.faceRecognitionEnabled;
    } catch (error) {
      console.error('Error checking demo mode status:', error);
      return true; // Default to demo mode on error
    }
  }

  // Process frame in demo mode
  private async processDemoFrameRecognition(
    frame: VideoFrame, 
    config: CameraStreamConfig
  ): Promise<RecognitionResult | null> {
    try {
      // Get demo children for this venue
      const demoChildren = await prisma.child.findMany({
        where: {
          currentVenueId: config.venueId
        },
        select: {
          id: true,
          firstName: true,
          lastName: true
        },
        take: 6 // Limit to 6 children for demo
      });

      if (demoChildren.length === 0) {
        // Use default demo children if none in database
        const defaultDemoChildren = [
          { id: 'demo-1', firstName: 'Emma', lastName: 'Johnson' },
          { id: 'demo-2', firstName: 'Michael', lastName: 'Chen' },
          { id: 'demo-3', firstName: 'Sofia', lastName: 'Martinez' },
          { id: 'demo-4', firstName: 'Marcus', lastName: 'Thompson' }
        ];

        // 40% chance of recognition per frame
        if (Math.random() > 0.6) {
          const activeChildren = defaultDemoChildren
            .filter(() => Math.random() > 0.5) // Random selection
            .slice(0, 1 + Math.floor(Math.random() * 2)); // 1-2 children

          const recognitions = activeChildren.map(child => ({
            childId: child.id,
            childName: `${child.firstName} ${child.lastName}`,
            confidence: 0.82 + Math.random() * 0.16, // 82-98% confidence
            boundingBox: {
              left: Math.random() * 0.7,
              top: Math.random() * 0.7,
              width: 0.08 + Math.random() * 0.08,
              height: 0.08 + Math.random() * 0.08
            },
            zone: config.zone || this.getRandomZone()
          }));

          return {
            frameId: frame.frameId,
            cameraId: frame.cameraId,
            recognitions,
            timestamp: frame.timestamp,
            processingTime: 0
          };
        }
      } else {
        // Use actual children for demo simulation
        if (Math.random() > 0.6) {
          const activeChildren = demoChildren
            .filter(() => Math.random() > 0.5)
            .slice(0, 1 + Math.floor(Math.random() * 2));

          const recognitions = activeChildren.map(child => ({
            childId: child.id,
            childName: `${child.firstName} ${child.lastName}`,
            confidence: 0.82 + Math.random() * 0.16,
            boundingBox: {
              left: Math.random() * 0.7,
              top: Math.random() * 0.7,
              width: 0.08 + Math.random() * 0.08,
              height: 0.08 + Math.random() * 0.08
            },
            zone: config.zone || this.getRandomZone()
          }));

          return {
            frameId: frame.frameId,
            cameraId: frame.cameraId,
            recognitions,
            timestamp: frame.timestamp,
            processingTime: 0
          };
        }
      }

      return null;
    } catch (error) {
      console.error('Error in demo frame recognition:', error);
      return null;
    }
  }

  // Get random zone for demo
  private getRandomZone(): string {
    const zones = [
      'Play Area A', 'Play Area B', 'Climbing Zone', 
      'Ball Pit', 'Toddler Area', 'Reading Corner',
      'Art Station', 'Main Entrance', 'Cafe Area'
    ];
    return zones[Math.floor(Math.random() * zones.length)];
  }

  // Handle recognition results
  private async handleRecognitionResult(result: RecognitionResult): Promise<void> {
    try {
      // Store results in memory for quick access
      const cameraResults = this.recognitionResults.get(result.cameraId) || [];
      cameraResults.push(result);
      
      // Keep only last 50 results per camera
      if (cameraResults.length > 50) {
        cameraResults.shift();
      }
      this.recognitionResults.set(result.cameraId, cameraResults);

      // Create database records for each recognition
      for (const recognition of result.recognitions) {
        try {
          await prisma.faceRecognitionEvent.create({
            data: {
              childId: recognition.childId,
              venueId: this.activeStreams.get(result.cameraId)?.venueId || '',
              sourceImageUrl: `frame://${result.frameId}`,
              sourceImageKey: result.frameId,
              confidence: recognition.confidence,
              boundingBox: recognition.boundingBox,
              eventType: 'FACE_MATCHED',
              processingTime: result.processingTime,
              recognitionData: {
                cameraId: result.cameraId,
                zone: recognition.zone,
                timestamp: result.timestamp.toISOString(),
                frameId: result.frameId
              }
            }
          });

          // Update child location
          await this.updateChildLocation(recognition, result);
        } catch (error) {
          console.error('Error creating face recognition event:', error);
        }
      }

      // Broadcast real-time updates via WebSocket
      await this.broadcastRecognitionUpdate(result);

    } catch (error) {
      console.error('Error handling recognition result:', error);
    }
  }

  // Update child location tracking
  private async updateChildLocation(
    recognition: RecognitionResult['recognitions'][0], 
    result: RecognitionResult
  ): Promise<void> {
    try {
      const config = this.activeStreams.get(result.cameraId);
      if (!config) return;

      await prisma.childLocationHistory.create({
        data: {
          childId: recognition.childId,
          venueId: config.venueId,
          location: {
            cameraId: result.cameraId,
            coordinates: recognition.boundingBox,
            zone: recognition.zone || 'Unknown Zone'
          },
          zone: recognition.zone,
          confidence: recognition.confidence,
          source: 'CAMERA',
          sourceId: result.cameraId,
          activity: 'detected'
        }
      });
    } catch (error) {
      console.error('Error updating child location:', error);
    }
  }

  // Broadcast real-time recognition updates
  private async broadcastRecognitionUpdate(result: RecognitionResult): Promise<void> {
    try {
      const config = this.activeStreams.get(result.cameraId);
      if (!config) return;

      // Broadcast to venue staff and parents
      await webSocketService.broadcastToVenue(config.venueId, {
        type: 'face_recognition_update',
        cameraId: result.cameraId,
        recognitions: result.recognitions.map(r => ({
          childId: r.childId,
          childName: r.childName,
          confidence: r.confidence,
          zone: r.zone,
          timestamp: result.timestamp.toISOString()
        })),
        timestamp: result.timestamp.toISOString()
      });

      // Send notifications to parents
      for (const recognition of result.recognitions) {
        const child = await prisma.child.findUnique({
          where: { id: recognition.childId },
          include: { parent: true }
        });

        if (child?.parent) {
          await webSocketService.sendToClient(child.parent.id, {
            type: 'child_detected',
            childId: recognition.childId,
            childName: recognition.childName,
            location: recognition.zone,
            confidence: recognition.confidence,
            cameraId: result.cameraId,
            timestamp: result.timestamp.toISOString()
          });
        }
      }
    } catch (error) {
      console.error('Error broadcasting recognition update:', error);
    }
  }

  // Get recent recognition results for a camera
  getRecentRecognitions(cameraId: string, limit: number = 10): RecognitionResult[] {
    const results = this.recognitionResults.get(cameraId) || [];
    return results.slice(-limit);
  }

  // Get all active camera streams
  getActiveStreams(): CameraStreamConfig[] {
    return Array.from(this.activeStreams.values());
  }

  // Stop camera stream processing
  async stopCameraStream(cameraId: string): Promise<void> {
    this.activeStreams.delete(cameraId);
    this.processingQueue.delete(cameraId);
    this.recognitionResults.delete(cameraId);
    console.log(`Camera stream stopped for ${cameraId}`);
  }

  // Simulate demo video frame processing
  async simulateDemoRecognition(cameraId: string, venueId: string): Promise<void> {
    try {
      // Get demo children for simulation
      const demoChildren = [
        { id: 'demo-1', name: 'Emma Johnson', zone: 'Play Area A' },
        { id: 'demo-2', name: 'Michael Chen', zone: 'Climbing Zone' },
        { id: 'demo-3', name: 'Sofia Martinez', zone: 'Ball Pit' },
        { id: 'demo-4', name: 'Marcus Thompson', zone: 'Toddler Area' }
      ];

      // Simulate random recognitions
      const activeChildren = demoChildren
        .filter(() => Math.random() > 0.4) // 60% chance each child is detected
        .slice(0, 2 + Math.floor(Math.random() * 2)); // 2-3 children max

      if (activeChildren.length === 0) return;

      const simulatedResult: RecognitionResult = {
        frameId: `demo-${Date.now()}`,
        cameraId,
        recognitions: activeChildren.map(child => ({
          childId: child.id,
          childName: child.name,
          confidence: 0.85 + Math.random() * 0.14, // 85-99% confidence
          boundingBox: {
            left: Math.random() * 0.7,
            top: Math.random() * 0.7,
            width: 0.1 + Math.random() * 0.1,
            height: 0.1 + Math.random() * 0.1
          },
          zone: child.zone
        })),
        timestamp: new Date(),
        processingTime: 150 + Math.random() * 100 // 150-250ms processing time
      };

      // Broadcast demo recognition
      await webSocketService.broadcastToVenue(venueId, {
        type: 'demo_face_recognition_update',
        cameraId,
        recognitions: simulatedResult.recognitions,
        timestamp: simulatedResult.timestamp.toISOString(),
        demo: true
      });

    } catch (error) {
      console.error('Error in demo recognition simulation:', error);
    }
  }
}

// Export singleton instance
export const realTimeFaceRecognitionService = RealTimeFaceRecognitionService.getInstance();
